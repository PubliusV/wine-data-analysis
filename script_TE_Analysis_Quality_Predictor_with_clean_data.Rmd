---
title: "script_TE_Analysis_quality"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
pacman::p_load(magrittr, tidyverse, fpp2, scales, DataExplorer, ggplot2, dplyr, kableExtra, outliers,ROCR,pROC,ranger)

```


## Load and Prepare Data
1. Load Training Data
2. Load Testing Data
3. Reformat response variable for modeling

### 1. Load Training Data
```{r load_data}
X_train = read.csv("data_wine_X_train.csv")
y_train = read.csv("data_wine_y_train.csv")

```

### 2. Load Test/Validation Data
``` {r}
X_test = read.csv("data_wine_X_test.csv")
y_test = read.csv("data_wine_y_test.csv")

```

### 3. Format Response as Factor and Relevel so "not_good" is the reference case.
```{r}
y_train$qual_good_7 = as.factor(y_train$qual_good_7)
y_test$qual_good_7 = as.factor(y_test$qual_good_7)

y_train$qual_good_7 = relevel(x=y_train$qual_good_7, ref = "not_good")
y_test$qual_good_7 = relevel(x=y_test$qual_good_7, ref = "not_good")
```


## Full Logistic Model

We want to get a baseline of model performance as well as understand which variables might be most important to a model. Therefore, we'll start by building a logistic model which uses all available features to predict wine quality.

```{r}
 library(caret)
  ctrl<-trainControl(method="none", summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)

# Full Logistic Model #
  lrfull<-caret::train(X_train, y_train$qual_good_7, method="glm", family="binomial", metric="ROC", trControl=ctrl)
  options(scipen = 999)
  lrfull$finalModel$coefficients
```

```{r, echo=FALSE}
summary(lrfull)
```

### Generate and Store Training Predictions
We want to store the predictions our model made while training so we can evaluate them later.

```{r}
lrf.training.predictions <-predict.train(lrfull, type="prob")
  head(lrf.training.predictions)
```

### Training: ROC Curve and Area Under the Curve
```{r}
library(pROC)  
lrf.training.roc<-roc(y_train$qual_good_7, lrf.training.predictions[,2])
lrf.training.roc$auc
```

### Generate and Store Test Predictions
```{r}
lrf.test.predictions<-predict.train(lrfull, newdata=X_test, type="prob")
head(lrf.test.predictions)
```

### Test: ROC Curve and Area Under the Curve
```{r}
  lrf.test.roc<-roc(y_test$qual_good_7, lrf.test.predictions[,2] )
  lrf.test.roc$auc
```

```{r echo=FALSE}
vPred_full = predict(lrfull,X_test,type = "prob")
```

## Stepwise Logistic Regression
Now we build an optimized logistic regression model. Stepwise regression optimizes the model by adding and subtracting features based on a performance metric (in this case the area under the ROC curve)

```{r}
lrstep<-caret::train(X_train,y_train$qual_good_7, method="glmStepAIC", direction="both", metric="ROC", trControl=ctrl, trace=0)
summary(lrstep)
```

### Train: Generate Predictions and ROC
```{r}
  lrs.training.predictions<-predict.train(lrstep, type="prob")
  lrs.training.roc<-roc(y_train$qual_good_7, lrs.training.predictions[,2])
  lrs.training.roc$auc
```

### Test: Generate Predictions and ROC
```{r}
 lrs.test.predictions<-predict.train(lrstep, newdata=X_test, type="prob")
 lrs.test.roc<-roc(y_test$qual_good_7, lrs.test.predictions[,2] )
 lrs.test.roc$auc
```

```{r echo=FALSE}
  # I think i use the predict method here instead of predict.train because of a weird interaction with one of the ROC packages.
 vPred_step = predict(lrstep,X_test, type = "prob")
```

## Advanced Models
Let's build a cross-validated random forest model and a XGBoost classifier.

### Random Forest
Load a joined version of the data (cross validating creates its own train/test split)
```{r}
X_full = read.csv("data_wine_X_SMOTE.csv")
y_full = read.csv("data_wine_y_SMOTE.csv")

reference_df = read.csv("data_wine_master_final.csv")
reference_df$y = as.factor(reference_df$y)
reference_df$y = relevel(x=reference_df$y, ref = "not_good")
reference_df$wine_type = as.factor(reference_df$wine_type)
reference_df$wine_type = relevel(x=reference_df$wine_type, ref = "white")
reference_df$wine_type = as.numeric(reference_df$wine_type)

reference_df = reference_df[ , -which(names(reference_df) %in% c("quality"))]

y_full$qual_good_7 = as.factor(y_full$qual_good_7)

y_full$qual_good_7 = relevel(x=y_full$qual_good_7, ref = "not_good")

```

```{r}
fitControl <- trainControl(method = "cv",number = 10,classProbs=TRUE)

forest = caret::train(X_train,y_train$qual_good_7, method = "ranger",trControl = fitControl,
  tuneGrid = expand.grid(.mtry = 2,.splitrule = "gini",.min.node.size=10),importance='impurity')

```


```{r}
evaluation_data_train = X_train
evaluation_data_train$y = y_train$qual_good_7

library(mlr)
task = makeClassifTask(data = evaluation_data_train, target = "y")

#xgboost model
lrn = makeLearner("classif.xgboost", predict.type = "prob", par.vals = list(
    objective = "binary:logistic",
    max_depth = 8,
    eta=0.1,
    nrounds = 300
  ))
xgb = train(lrn, task)
```


## Model Comparison



### Lift Chart -- Full vs. Stepwise regression on Test Data
```{r, echo=FALSE}
library(modelplotr)
```
```{r}
# transform datasets and model objects into scored data and calculate deciles 


evaluation_data_test = X_test
evaluation_data_test$y = y_test$qual_good_7

eval_df = prepare_scores_and_ntiles(datasets=list("evaluation_data_train","evaluation_data_test","reference_df"),
  dataset_labels = list("train data","test data", "original data"),
  models = list("lrfull","lrstep","forest","xgb"),
  model_labels = list("Full Logistic Regression","Stepwise Logistic Regression","Random Forest","Gradient Boosted Trees"),
  target_column="y",
  ntiles = 100
  )

eval_plots = plotting_scope(prepared_input = eval_df,
               scope = "compare_models",
               select_dataset_label = "test data"
               )
ref_plots = plotting_scope(
  prepared_input = eval_df,
  scope = "no_comparison",
  select_model_label = "Gradient Boosted Trees",
  select_dataset_label = "original data"
)
```


```{r}
plot_cumgains(data = eval_plots, highlight_ntile = 30)
```

```{r}
plot_cumlift(data = eval_plots, highlight_ntile = 30)
```

```{r}
plot_response(data = eval_plots, highlight_ntile = 29)
```

```{r}
plot_cumresponse(data = eval_plots, highlight_ntile = 29)
```

## Performance on Original Data
```{r}
plot_cumgains(data = ref_plots, highlight_ntile = 3)
```

```{r}
plot_cumlift(data = ref_plots, highlight_ntile = 3)
```

```{r}
plot_response(data = ref_plots, highlight_ntile = 3)
```

```{r}
plot_cumresponse(data = ref_plots, highlight_ntile = 3)
```

```{r}
Forest_Importance = ranger::importance(forest$finalModel)


xgb_varImp = xgboost::xgb.importance(colnames(X_train), model = xgb$learner.model)
xgb_varImp
```

